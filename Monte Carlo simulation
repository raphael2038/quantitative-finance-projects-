!pip install colorama
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
from itertools import product
from colorama import Fore

# Helper function to print adjacency matrix (useful for debug )
def print_matrix(G):
    for i, j in product(range(G.shape[0]), range(G.shape[1])):
        ending = "\n" if j == G.shape[0]-1 else ""
        if G[i, j] == 0:
            print(Fore.WHITE, f'{round(G[i, j], 2)}', end=ending)
        if G[i, j] > 0:
            print(Fore.GREEN, f'{round(G[i, j], 2)}', end=ending)

def plot_network(G):
    graph = nx.from_numpy_array(G, create_using=nx.DiGraph())
    pos = nx.spring_layout(graph)
    nx.draw(graph, pos, with_labels=True, node_size=100, font_size=5)
    plt.show()

# Generate a fully connected graph (to understand if the  correlation between assets)
def full_mesh(inodes):
    G = np.ones((inodes, inodes))
    np.fill_diagonal(G, 0)
    return G.astype(int)

# here we are computing probabilities based on number of connections
def compute_p(G):
    p = []
    all_connections = np.count_nonzero(G)
    for row_index in range(len(G)):
        connections_node_i = np.count_nonzero(G[row_index])
        p.append(connections_node_i/all_connections)
    return p

def asset_selection(G, m):
    p = compute_p(G)
    assets = np.random.choice(range(len(G[0])), m, p=p)
    return assets

# Barabási–Albert model to create  a network of asset correlations
def BA_model(initial_size, m, final_size):
    G = full_mesh(initial_size)
    while initial_size < final_size:
        assets = asset_selection(G, m)
        column = np.zeros(len(G) + 1)
        row = np.zeros(len(G))
        for asset in assets:
            column[int(asset)] = 1
            row[int(asset)] = 1
        G = np.vstack([G, row])
        G = np.column_stack([G, column])
        G = G.astype(int)
        initial_size += 1
    return G

# Normalize out-degree for better financial interpretation (asset correlation normalization)
def normalize_out_degree(G):
    column_sums = np.sum(G, axis=0)
    column_sums[column_sums == 0] = 1e-8  # Avoid division by zero
    norm_matrix = 1 / column_sums
    new_G = G * norm_matrix
    return new_G

def plot_degree_histogram(G):
    degrees = np.sum(G, axis=0)
    unique, counts = np.unique(degrees, return_counts=True)
    plt.bar(unique, counts)
    plt.xlabel('Asset Correlation Degree')
    plt.ylabel('Number of Assets')
    plt.title('Asset Correlation Distribution')
    plt.xticks(unique)
    plt.ylim(0, max(counts))
    plt.show()

def initial_shock(all_assets):
    states = np.array(['s'] * all_assets)
    initial_shocked = 2
    shocked_indices = np.random.choice(all_assets, initial_shocked, replace=False)
    for element in shocked_indices:
        states[element] = 'i'
    return states

# Propagation of shocks or volatility through the market (similar to SIS)
def propagation_step(G, states, mu, beta):
    new_prob = np.zeros(len(states))
    states_numeric = [0 if state == 's' else 1 for state in states]
    for asset in range(len(G[0])):
        adj_assets = G[asset]
        neighbors = np.where(adj_assets > 0)[0]
        q = 1
        for neighbor in neighbors:
            q *= (1 - (beta * G[neighbor][asset] * states_numeric[neighbor]))
        new_prob[asset] = (1 - q) * (1 - states_numeric[asset]) + (1 - mu) * states_numeric[asset] + mu * (1 - q) * states_numeric[asset]
    return new_prob

def new_state_assets(prob, states):
    random_numbers = np.random.random(size=len(prob))
    states = np.where(prob > random_numbers, 'i', 's')
    return states

def run_simulation(G, steps, mu, beta):
    states = initial_shock(G.shape[0])
    proportion_shocked = np.zeros(steps)
    for step in range(steps):
        new_prob = propagation_step(G, states, mu, beta)
        states = new_state_assets(new_prob, states)
        shocked_count = np.count_nonzero(states == 'i')
        proportion_shocked[step] = shocked_count / G.shape[0]
    return proportion_shocked

#  these simulations are made for portfolio risk assessment
def run_multiple_simulations(G, num_simulations, steps, mu, beta):
    all_proportions = np.zeros((num_simulations, steps))
    for i in range(num_simulations):
        all_proportions[i] = run_simulation(G, steps, mu, beta)
    average_proportions = np.mean(all_proportions, axis=0)
    return average_proportions

#the following data are purely random and do not reflect the real data 
graph_templates = [(2, 0.5), (2, 3), (8, 0.5), (8, 3), (40, 0.5), (40, 3)]
mu = 0.5  # Recovery rate 

plt.figure(figsize=(10, 6))
for initial_shocked, mu_beta_ratio in graph_templates:
    beta = mu_beta_ratio * mu
    all_networks_averages = np.zeros((10, 30))
    for i in range(10):
        graph = BA_model(3, 2, 40)
        graph = normalize_out_degree(graph)
        average_proportions = run_multiple_simulations(graph, 50, 30, mu, beta)
        all_networks_averages[i] = average_proportions
    overall_average = np.mean(all_networks_averages, axis=0)
    plt.plot(overall_average, label=f'Initial Shocked={initial_shocked}, beta={beta:.2f}')

plt.xlabel('Step')
plt.ylabel('Average Proportion of Shocked Assets')
plt.title(f'Average Shock Propagation Across 10 Networks (mu={mu})')
plt.legend()
plt.show()








Time complexity:O(num_simulations×steps×final_size²)
Space complexity:O(final_size²)
